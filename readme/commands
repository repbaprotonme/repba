du -h *  #human readable disk usage
scp 0* scott@reportbase.com:/srv/http/data/boss #transfer files
grep -r --include "*.ini" "#auto" . #recursive find
sed -r 's/\s+//g' filename  #clear whitespace
find . -type f -name $1  #find file
sed -i 's/\.//g' meta.ini #clear periods
sed '/url=/d' meta.ini #delete line from ini
find data/ -name '*.json' -exec cat {} \; > uber.json   #recurse folders concat them
rename "s/oldExtension$/newExtension/" *.txt   #rename all files
mkdir -p 00{00..72}  #make multiple directories
FOLDER=$(printf "%04d" "$i")
find . -name "*.png" -exec convert "{}" -alpha off "{}" \; #remove alpha channel from all images in folder

ls -laS #sort by size. largest on top                                                                                                                                                    

# This is GOLD for finding out what is taking so much space on your drives!
alias diskspace="du -S | sort -n -r |more"

# Show me the size (sorted) of only the folders in this directory
alias folders="find . -maxdepth 1 -type d -print | xargs du -sk | sort -rn"

# rar cbr
unrar x ~/file.rar

#unsplash get randome image
wget -q -O unsplash_wallpaper.jpg https://unsplash.it/1920/1080/?random

#get images
for i in {1..25}; do wget https://source.unsplash.com/featured/\?dogs?orientation=portrait -O "$(ls -l | wc -l).jpg" && sleep 2; done

#how many cores
cat /proc/cpuinfo

#replace all strings in folder
sed -i 's/list/data/g' *

#resize images no bigger than 60000000
for file in *.webp; do convert $file -resize '6000000@>' $file; done

#animated gif
convert -resize 50% -delay 100 -loop 0 001*.jpg anim.gif
